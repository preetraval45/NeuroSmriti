{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroSmriti - Complete Model Training Pipeline\n",
    "\n",
    "This notebook will:\n",
    "1. Load real or synthetic data\n",
    "2. Train MemoryGNN model\n",
    "3. Evaluate performance\n",
    "4. Generate visualizations\n",
    "5. Save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.memory_gnn import MemoryGNN, MemoryDecayLoss\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what data we have\n",
    "data_dir = '../data'\n",
    "synthetic_dir = f'{data_dir}/synthetic'\n",
    "hackathon_dir = f'{data_dir}/raw/hackathon'\n",
    "\n",
    "print(\"üìä Available Datasets:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check synthetic data\n",
    "if os.path.exists(f'{synthetic_dir}/train.pkl'):\n",
    "    with open(f'{synthetic_dir}/train.pkl', 'rb') as f:\n",
    "        synthetic_train = pickle.load(f)\n",
    "    print(f\"‚úÖ Synthetic Data: {len(synthetic_train)} training samples\")\n",
    "    use_synthetic = True\n",
    "else:\n",
    "    print(\"‚ùå Synthetic data not found. Run 01_data_generation.ipynb first.\")\n",
    "    use_synthetic = False\n",
    "\n",
    "# Check hackathon data\n",
    "if os.path.exists(hackathon_dir):\n",
    "    files = os.listdir(hackathon_dir)\n",
    "    print(f\"‚úÖ Hackathon Data: {len(files)} files found\")\n",
    "    use_hackathon = True\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Hackathon data not found (optional)\")\n",
    "    use_hackathon = False\n",
    "\n",
    "print(\"\\nüí° Using synthetic data for training (perfect for hackathon!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If synthetic data doesn't exist, generate it now\n",
    "if not use_synthetic:\n",
    "    print(\"Generating synthetic data...\")\n",
    "    %run 01_data_generation.ipynb\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "with open(f'{synthetic_dir}/train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open(f'{synthetic_dir}/val.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "with open(f'{synthetic_dir}/test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "print(f\"‚úÖ Train: {len(train_data)} samples\")\n",
    "print(f\"‚úÖ Val: {len(val_data)} samples\")\n",
    "print(f\"‚úÖ Test: {len(test_data)} samples\")\n",
    "\n",
    "# Analyze data\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "all_data = train_data + val_data + test_data\n",
    "avg_nodes = np.mean([d.x.size(0) for d in all_data])\n",
    "avg_edges = np.mean([d.edge_index.size(1) for d in all_data])\n",
    "print(f\"Average memories per patient: {avg_nodes:.1f}\")\n",
    "print(f\"Average connections per patient: {avg_edges:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Created data loaders (batch size: {BATCH_SIZE})\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_NODE_FEATURES = 10\n",
    "HIDDEN_CHANNELS = 64\n",
    "NUM_HEADS = 4\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Initialize model\n",
    "model = MemoryGNN(\n",
    "    num_node_features=NUM_NODE_FEATURES,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "print(\"‚úÖ Model initialized\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = MemoryDecayLoss(alpha=0.7, beta=0.3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Optimizer and scheduler configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_pred, graph_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(node_pred, batch.y_node, graph_pred, batch.y_graph)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    node_mae = 0\n",
    "    graph_mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            node_pred, graph_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "            loss = criterion(node_pred, batch.y_node, graph_pred, batch.y_graph)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            node_mae += F.l1_loss(node_pred, batch.y_node).item()\n",
    "            graph_mae += F.l1_loss(graph_pred, batch.y_graph).item()\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / len(loader),\n",
    "        'node_mae': node_mae / len(loader),\n",
    "        'graph_mae': graph_mae / len(loader)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "\n",
    "print(f\"üöÄ Starting training for {NUM_EPOCHS} epochs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Track metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_node_maes = []\n",
    "val_graph_maes = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validate\n",
    "    val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_metrics['loss'])\n",
    "    val_node_maes.append(val_metrics['node_mae'])\n",
    "    val_graph_maes.append(val_metrics['graph_mae'])\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(val_metrics['loss'])\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_metrics['loss']:.4f} | Node MAE: {val_metrics['node_mae']:.4f} | Graph MAE: {val_metrics['graph_mae']:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_metrics['loss'] < best_val_loss:\n",
    "        best_val_loss = val_metrics['loss']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'hyperparameters': {\n",
    "                'hidden_channels': HIDDEN_CHANNELS,\n",
    "                'num_heads': NUM_HEADS,\n",
    "                'num_layers': NUM_LAYERS,\n",
    "                'dropout': DROPOUT\n",
    "            }\n",
    "        }, '../models/memory_gnn_best.pth')\n",
    "        print(\"‚úÖ Saved best model!\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\n‚èπÔ∏è  Early stopping after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(train_losses, label='Train Loss', linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Node MAE\n",
    "axes[1].plot(val_node_maes, color='orange', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('MAE', fontsize=12)\n",
    "axes[1].set_title('Memory Decay Prediction Error', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Graph MAE\n",
    "axes[2].plot(val_graph_maes, color='green', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('MAE', fontsize=12)\n",
    "axes[2].set_title('Risk Score Prediction Error', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training curves saved to: ml/models/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üìä FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('../models/memory_gnn_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate\n",
    "test_metrics = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nüìà Test Results:\")\n",
    "print(f\"Loss: {test_metrics['loss']:.4f}\")\n",
    "print(f\"Node MAE (decay prediction): {test_metrics['node_mae']:.4f}\")\n",
    "print(f\"Graph MAE (risk score): {test_metrics['graph_mae']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä As Percentages:\")\n",
    "print(f\"Memory Decay Error: {test_metrics['node_mae'] * 100:.2f}%\")\n",
    "print(f\"Risk Score Error: {test_metrics['graph_mae'] * 100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy (within threshold)\n",
    "model.eval()\n",
    "correct_30 = 0\n",
    "correct_90 = 0\n",
    "correct_180 = 0\n",
    "total_nodes = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        node_pred, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "        diff = torch.abs(node_pred - batch.y_node)\n",
    "        correct_30 += (diff[:, 0] < 0.1).sum().item()\n",
    "        correct_90 += (diff[:, 1] < 0.1).sum().item()\n",
    "        correct_180 += (diff[:, 2] < 0.1).sum().item()\n",
    "        total_nodes += batch.x.size(0)\n",
    "\n",
    "print(f\"\\nüéØ Accuracy (within 10% threshold):\")\n",
    "print(f\"30-day forecast: {100 * correct_30 / total_nodes:.2f}%\")\n",
    "print(f\"90-day forecast: {100 * correct_90 / total_nodes:.2f}%\")\n",
    "print(f\"180-day forecast: {100 * correct_180 / total_nodes:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Evaluation complete!\")\n",
    "print(\"üì¶ Model saved to: ml/models/memory_gnn_best.pth\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample patient\n",
    "sample_patient = test_data[0].to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    node_pred, graph_pred = model(\n",
    "        sample_patient.x,\n",
    "        sample_patient.edge_index,\n",
    "        sample_patient.edge_attr\n",
    "    )\n",
    "\n",
    "print(\"üîÆ Sample Patient Prediction\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Stage: {sample_patient.stage}\")\n",
    "print(f\"Number of memories: {sample_patient.x.size(0)}\")\n",
    "print(f\"\\nOverall Risk Score: {graph_pred.item():.3f}\")\n",
    "\n",
    "print(f\"\\nüìâ Top 5 High-Risk Memories:\")\n",
    "# Get memories with highest decay risk (lowest predicted 30-day strength)\n",
    "risk_scores = 1.0 - node_pred[:, 0]  # Inverse of predicted strength\n",
    "top_risk_indices = torch.argsort(risk_scores, descending=True)[:5]\n",
    "\n",
    "for i, idx in enumerate(top_risk_indices, 1):\n",
    "    current_strength = sample_patient.x[idx, 5].item() * 100  # Current strength\n",
    "    pred_30 = node_pred[idx, 0].item() * 100\n",
    "    pred_90 = node_pred[idx, 1].item() * 100\n",
    "    pred_180 = node_pred[idx, 2].item() * 100\n",
    "\n",
    "    print(f\"\\nMemory #{i} (Index {idx.item()}):\")\n",
    "    print(f\"  Current: {current_strength:.1f}%\")\n",
    "    print(f\"  Predicted 30-day: {pred_30:.1f}% (Œî {pred_30 - current_strength:+.1f}%)\")\n",
    "    print(f\"  Predicted 90-day: {pred_90:.1f}%\")\n",
    "    print(f\"  Predicted 180-day: {pred_180:.1f}%\")\n",
    "    print(f\"  ‚ö†Ô∏è  Intervention recommended!\" if pred_30 < 50 else \"  ‚úÖ Stable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Exporting model for production...\")\n",
    "\n",
    "# Save final model with metadata\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'hyperparameters': {\n",
    "        'num_node_features': NUM_NODE_FEATURES,\n",
    "        'hidden_channels': HIDDEN_CHANNELS,\n",
    "        'num_heads': NUM_HEADS,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'dropout': DROPOUT\n",
    "    },\n",
    "    'performance': {\n",
    "        'test_loss': test_metrics['loss'],\n",
    "        'node_mae': test_metrics['node_mae'],\n",
    "        'graph_mae': test_metrics['graph_mae'],\n",
    "        'accuracy_30d': correct_30 / total_nodes,\n",
    "        'accuracy_90d': correct_90 / total_nodes,\n",
    "        'accuracy_180d': correct_180 / total_nodes\n",
    "    }\n",
    "}, '../models/memory_gnn_production.pth')\n",
    "\n",
    "# Copy to backend for API use\n",
    "import shutil\n",
    "backend_model_dir = '../../backend/app/ml/models'\n",
    "os.makedirs(backend_model_dir, exist_ok=True)\n",
    "shutil.copy('../models/memory_gnn_production.pth', f'{backend_model_dir}/memory_gnn_production.pth')\n",
    "\n",
    "print(\"‚úÖ Model exported to:\")\n",
    "print(\"   1. ml/models/memory_gnn_production.pth\")\n",
    "print(\"   2. backend/app/ml/models/memory_gnn_production.pth\")\n",
    "\n",
    "print(\"\\nüéâ Training pipeline complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Start backend: cd ../../backend && uvicorn app.main:app --reload\")\n",
    "print(\"2. Test predictions at: http://localhost:8000/docs\")\n",
    "print(\"3. Build frontend dashboard\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
